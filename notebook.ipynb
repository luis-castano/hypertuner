{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/keras/keras_tuner#define_the_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer. Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer. Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='tuners',\n",
    "    project_name='hypertuner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 38s]\n",
      "val_accuracy: 0.8841666579246521\n",
      "\n",
      "Best val_accuracy So Far: 0.8944166898727417\n",
      "Total elapsed time: 00h 07m 48s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected layer is 512 and the optimal learning rate for the optimizer is 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    img_train,\n",
    "    label_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early]\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f'''\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected layer is {best_hps.get('units')} and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4906 - accuracy: 0.8261 - val_loss: 0.4191 - val_accuracy: 0.8432\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3698 - accuracy: 0.8660 - val_loss: 0.3473 - val_accuracy: 0.8728\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3280 - accuracy: 0.8784 - val_loss: 0.3455 - val_accuracy: 0.8748\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3056 - accuracy: 0.8872 - val_loss: 0.3411 - val_accuracy: 0.8767\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2848 - accuracy: 0.8952 - val_loss: 0.3299 - val_accuracy: 0.8822\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2683 - accuracy: 0.9010 - val_loss: 0.3213 - val_accuracy: 0.8866\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2570 - accuracy: 0.9048 - val_loss: 0.3225 - val_accuracy: 0.8873\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2442 - accuracy: 0.9101 - val_loss: 0.3172 - val_accuracy: 0.8904\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2341 - accuracy: 0.9125 - val_loss: 0.3261 - val_accuracy: 0.8841\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2250 - accuracy: 0.9148 - val_loss: 0.3197 - val_accuracy: 0.8888\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2141 - accuracy: 0.9203 - val_loss: 0.3036 - val_accuracy: 0.8941\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2091 - accuracy: 0.9220 - val_loss: 0.3147 - val_accuracy: 0.8928\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.3146 - val_accuracy: 0.8916\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1898 - accuracy: 0.9280 - val_loss: 0.3252 - val_accuracy: 0.8913\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9309 - val_loss: 0.3551 - val_accuracy: 0.8877\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1797 - accuracy: 0.9317 - val_loss: 0.3220 - val_accuracy: 0.8921\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1721 - accuracy: 0.9360 - val_loss: 0.3353 - val_accuracy: 0.8910\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1643 - accuracy: 0.9384 - val_loss: 0.3475 - val_accuracy: 0.8927\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1605 - accuracy: 0.9390 - val_loss: 0.3494 - val_accuracy: 0.8917\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1542 - accuracy: 0.9419 - val_loss: 0.3712 - val_accuracy: 0.8893\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1529 - accuracy: 0.9430 - val_loss: 0.3735 - val_accuracy: 0.8905\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1456 - accuracy: 0.9446 - val_loss: 0.3624 - val_accuracy: 0.8952\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1426 - accuracy: 0.9471 - val_loss: 0.3875 - val_accuracy: 0.8875\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1392 - accuracy: 0.9475 - val_loss: 0.3927 - val_accuracy: 0.8925\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1326 - accuracy: 0.9502 - val_loss: 0.3654 - val_accuracy: 0.8957\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1275 - accuracy: 0.9521 - val_loss: 0.4043 - val_accuracy: 0.8911\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.4064 - val_accuracy: 0.8882\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1215 - accuracy: 0.9534 - val_loss: 0.3859 - val_accuracy: 0.8981\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1179 - accuracy: 0.9554 - val_loss: 0.3869 - val_accuracy: 0.8957\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1179 - accuracy: 0.9564 - val_loss: 0.4106 - val_accuracy: 0.8984\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1138 - accuracy: 0.9569 - val_loss: 0.3820 - val_accuracy: 0.8961\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1074 - accuracy: 0.9597 - val_loss: 0.4316 - val_accuracy: 0.8885\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1090 - accuracy: 0.9597 - val_loss: 0.4140 - val_accuracy: 0.8943\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1043 - accuracy: 0.9599 - val_loss: 0.4297 - val_accuracy: 0.8953\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1025 - accuracy: 0.9610 - val_loss: 0.4386 - val_accuracy: 0.8945\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1022 - accuracy: 0.9613 - val_loss: 0.4305 - val_accuracy: 0.8992\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0985 - accuracy: 0.9634 - val_loss: 0.4642 - val_accuracy: 0.8955\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0967 - accuracy: 0.9637 - val_loss: 0.4630 - val_accuracy: 0.8917\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0905 - accuracy: 0.9663 - val_loss: 0.4566 - val_accuracy: 0.8967\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0903 - accuracy: 0.9661 - val_loss: 0.4851 - val_accuracy: 0.8919\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0911 - accuracy: 0.9663 - val_loss: 0.4764 - val_accuracy: 0.8923\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0864 - accuracy: 0.9673 - val_loss: 0.4718 - val_accuracy: 0.8956\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0859 - accuracy: 0.9677 - val_loss: 0.4748 - val_accuracy: 0.8948\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0863 - accuracy: 0.9678 - val_loss: 0.4826 - val_accuracy: 0.8946\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0811 - accuracy: 0.9695 - val_loss: 0.4765 - val_accuracy: 0.8979\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9691 - val_loss: 0.4772 - val_accuracy: 0.8935\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0785 - accuracy: 0.9707 - val_loss: 0.5353 - val_accuracy: 0.8911\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0770 - accuracy: 0.9711 - val_loss: 0.5133 - val_accuracy: 0.8938\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0752 - accuracy: 0.9715 - val_loss: 0.5538 - val_accuracy: 0.8956\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0761 - accuracy: 0.9727 - val_loss: 0.5542 - val_accuracy: 0.8886\n",
      "Best epoch: 36\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = model.fit(\n",
    "    img_train,\n",
    "    label_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print(f'Best epoch: {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4931 - accuracy: 0.8245 - val_loss: 0.3904 - val_accuracy: 0.8585\n",
      "Epoch 2/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3713 - accuracy: 0.8651 - val_loss: 0.4065 - val_accuracy: 0.8522\n",
      "Epoch 3/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3295 - accuracy: 0.8792 - val_loss: 0.3528 - val_accuracy: 0.8673\n",
      "Epoch 4/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3041 - accuracy: 0.8887 - val_loss: 0.3381 - val_accuracy: 0.8788\n",
      "Epoch 5/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2848 - accuracy: 0.8934 - val_loss: 0.3220 - val_accuracy: 0.8847\n",
      "Epoch 6/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2701 - accuracy: 0.8997 - val_loss: 0.3361 - val_accuracy: 0.8828\n",
      "Epoch 7/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2531 - accuracy: 0.9046 - val_loss: 0.3332 - val_accuracy: 0.8851\n",
      "Epoch 8/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2434 - accuracy: 0.9082 - val_loss: 0.3404 - val_accuracy: 0.8803\n",
      "Epoch 9/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2317 - accuracy: 0.9136 - val_loss: 0.3408 - val_accuracy: 0.8832\n",
      "Epoch 10/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2217 - accuracy: 0.9168 - val_loss: 0.3144 - val_accuracy: 0.8906\n",
      "Epoch 11/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2139 - accuracy: 0.9196 - val_loss: 0.3043 - val_accuracy: 0.8956\n",
      "Epoch 12/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2048 - accuracy: 0.9233 - val_loss: 0.3034 - val_accuracy: 0.8961\n",
      "Epoch 13/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1992 - accuracy: 0.9252 - val_loss: 0.3104 - val_accuracy: 0.8970\n",
      "Epoch 14/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1890 - accuracy: 0.9296 - val_loss: 0.3424 - val_accuracy: 0.8870\n",
      "Epoch 15/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1857 - accuracy: 0.9302 - val_loss: 0.3463 - val_accuracy: 0.8870\n",
      "Epoch 16/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1781 - accuracy: 0.9334 - val_loss: 0.3429 - val_accuracy: 0.8854\n",
      "Epoch 17/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1715 - accuracy: 0.9363 - val_loss: 0.3354 - val_accuracy: 0.8932\n",
      "Epoch 18/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1656 - accuracy: 0.9376 - val_loss: 0.3552 - val_accuracy: 0.8880\n",
      "Epoch 19/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1590 - accuracy: 0.9407 - val_loss: 0.3681 - val_accuracy: 0.8859\n",
      "Epoch 20/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1545 - accuracy: 0.9424 - val_loss: 0.3644 - val_accuracy: 0.8916\n",
      "Epoch 21/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1528 - accuracy: 0.9415 - val_loss: 0.3509 - val_accuracy: 0.8957\n",
      "Epoch 22/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1442 - accuracy: 0.9456 - val_loss: 0.3698 - val_accuracy: 0.8903\n",
      "Epoch 23/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1395 - accuracy: 0.9479 - val_loss: 0.3995 - val_accuracy: 0.8883\n",
      "Epoch 24/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1375 - accuracy: 0.9480 - val_loss: 0.3691 - val_accuracy: 0.8984\n",
      "Epoch 25/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1315 - accuracy: 0.9509 - val_loss: 0.4090 - val_accuracy: 0.8928\n",
      "Epoch 26/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1325 - accuracy: 0.9507 - val_loss: 0.3930 - val_accuracy: 0.8940\n",
      "Epoch 27/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1246 - accuracy: 0.9529 - val_loss: 0.3942 - val_accuracy: 0.8918\n",
      "Epoch 28/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1261 - accuracy: 0.9525 - val_loss: 0.4204 - val_accuracy: 0.8935\n",
      "Epoch 29/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1201 - accuracy: 0.9536 - val_loss: 0.4131 - val_accuracy: 0.8914\n",
      "Epoch 30/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1151 - accuracy: 0.9570 - val_loss: 0.4057 - val_accuracy: 0.8911\n",
      "Epoch 31/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1110 - accuracy: 0.9583 - val_loss: 0.4234 - val_accuracy: 0.8917\n",
      "Epoch 32/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1147 - accuracy: 0.9580 - val_loss: 0.4259 - val_accuracy: 0.8934\n",
      "Epoch 33/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9591 - val_loss: 0.4369 - val_accuracy: 0.8900\n",
      "Epoch 34/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1045 - accuracy: 0.9606 - val_loss: 0.4551 - val_accuracy: 0.8888\n",
      "Epoch 35/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1035 - accuracy: 0.9606 - val_loss: 0.4506 - val_accuracy: 0.8913\n",
      "Epoch 36/36\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1021 - accuracy: 0.9618 - val_loss: 0.4556 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c2a1d23d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(\n",
    "    img_train,\n",
    "    label_train,\n",
    "    epochs=best_epoch,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5137 - accuracy: 0.8882\n",
      "[Test loss, Test accuracy]: [0.5136528611183167, 0.8881999850273132]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(f'[Test loss, Test accuracy]: {eval_result}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cbee2bbfd58d43bfdb77c99552951933667bb17932117d62dbb0188bd99758d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hypertuner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
